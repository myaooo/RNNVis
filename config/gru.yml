model:
  name: GRU-PTB
  initializer_name: random_uniform
  initializer_args:
    minval: -0.04
    maxval: 0.04
  input_dtype: int32
  target_dtype: int32
  vocab_size: 10000
  embedding_size: 600
  cell_type: GRU
  cells:
    - num_units: 600
    - num_units: 600
  loss_func: sequence_loss
  dataset: ptb
train:
  epoch_num: 35
  num_steps: 40
  batch_size: 20
  keep_prob: 0.5
  gradient_clip: global_norm
  gradient_clip_args:
    clip_norm: 10.0
  optimizer: GradientDescent
  learning_rate: "lambda epoch: 1.0 *(1.0 if epoch < 6 else 0.82**(epoch-6))"

